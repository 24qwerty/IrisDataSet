import pandas as pd
names=['sepal_length','sepal_width','petal_length','petal_width',"class"]
df=pd.read_csv("/Users/shaily/Documents/Machine Learning Practice/K-Nearest Neighbour/iris.txt",header=None,names=names)
df.head()


from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
scatter_matrix(df)
plt.show()



pl1=df['petal_length'][df['class']=='Iris-setosa']
pw1=df['petal_width'][df['class']=='Iris-setosa']
pl2=df['petal_length'][df['class']=='Iris-versicolor']
pw2=df['petal_width'][df['class']=='Iris-versicolor']
pl3=df['petal_length'][df['class']=='Iris-virginica']
pw3=df['petal_width'][df['class']=='Iris-virginica']
f,g=plt.subplots()
g.scatter(pl1,pw1,color='r')
g.scatter(pl2,pw2,color='b')
g.scatter(pl3,pw3,color='g')
plt.show()


import numpy as np
from sklearn.cross_validation import train_test_split
X = np.array(df.ix[:, 0:4])
y = np.array(df['class']) 


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)


from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
pred = knn.predict(X_test)
print (accuracy_score(y_test, pred))


from sklearn.model_selection import cross_val_score
neighbors = list(range(1,50,2))
print(neighbors)
cv_scores = []
for k in neighbors:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')
    cv_scores.append(scores.mean())


MSE = [1 - x for x in cv_scores]
optimal_k = neighbors[MSE.index(min(MSE))]
print ("The optimal number of neighbors is %d" % optimal_k)
plt.plot(neighbors, MSE)
plt.xlabel('Number of Neighbors K')
plt.ylabel('Misclassification Error')
plt.show()
